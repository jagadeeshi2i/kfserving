apiVersion: serving.kubeflow.org/v1beta1
kind: InferenceService
metadata:
  name: "torchserve"
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/port: '8082'
spec:
  transformer:
    containers:
      - image: <username>/image-transformer:latest
        name: transformer-container
        env:
          - name: STORAGE_URI
            value: pvc://model-pv-claim
  predictor:
    pytorch:
      protocolVersion: v2
      storageUri: pvc://model-pv-claim
      resources:
        limits:
          cpu: 16
          memory: 16Gi
          nvidia.com/gpu: "1"
        requests:
          cpu: 16
          memory: 16Gi
          nvidia.com/gpu: "1"
