apiVersion: "serving.kubeflow.org/v1beta1"
kind: "InferenceService"
metadata:
  name: torchserve-custom
spec:
  predictor:
    containers:
    - image: jagadeeshj/ts_custom:latest
      name: torchserve-container
      ports:
        - containerPort: 8080
       